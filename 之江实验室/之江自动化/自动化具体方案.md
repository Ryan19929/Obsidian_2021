## 1.具体实现思路
1. 全部的流程都由auto.py来负责
2. 爬虫->auto.py->upload2hdfs->process->(java部分暂定)
3. 可以更改相关的数据！
## 2.爬虫
- 在爬虫执行结束的情况下，调用auto.py(filename)来执行接下的步骤
- filename是相关爬虫的名字
## 3.auto.py
- auto.py负责hadoop处理之前的全部流程
- 重新执行爬虫的命令要分开！！！
### 3.1相关流程 
- lunch_py(filename)
	1. 更换status表中的爬取日期
	2. 发送爬取成功命令
	3. 重启爬虫
- upload2hdfs(localpath,hdfspath)
	1. 上传爬好的数据到hdfs 
	2. inputpath是数据local的地址
	3. outputpath是数据hdfs的地址
- main(flag)
	- 主入口，用于区分专利和论文
	- flag=1 表示专利
	- flag=0 表示论文
	- 执行函数顺序upload2hdfs->lunch_jar
	- lunch_py由爬虫函数自己调用